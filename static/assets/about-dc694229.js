import{K as a,r as i,o as s,c as n,f as e,a as d,M as c}from"./index-9ffcd92b.js";const l={class:"prose prose-sm m-auto text-left"},r={class:"text-center"},u=e("h1",{class:"text-primary"},"Why AioFauna?",-1),h=c("<h2>What is AioFauna?</h2><p>It’s an opinionated full-stack framework for building Web Applications built on top of Aiohttp, Pydantic and FaunaDB and heavily influenced by FastAPI.</p><h2>Why AioFauna?</h2><h3>Why FaunaDB?</h3><p>The goal of the project is to build an Stack like MERN, LAMP or MEAN but with a python backend for full stack developers So picking the main database was the most crucial decission to make. I chose FaunaDB because is suitable for the widest variety of uses cases since it has the following characteristics:</p><ul><li>Is Serverless (No O&amp;M burden = NoOps)</li><li>It’s Globally distributed through a CDN so adding an additional layer of caching or message queueing will be optional and constrained to specific use cases.</li><li>Is timezone aware, so you can query data based on the user’s timezone.</li><li>Is document based and relational at the same time, so and ODM could be built on top of it.</li><li>It’s extensible through an expression based functional language (FQL) with a rich set of features, so you can build complex queries and mutations.</li><li>It has a generous Free Tier, so you can build a prototype or a small application without paying a dime.</li><li>It’s also a Graph based databse so it supports complex relational scenarios like social networks.</li><li><strong>q</strong>: <code>aiofauna</code> provides the <code>_Expr</code> object and FaunaClient as classmethods, so you can use the native driver directly to query your models from the class objects by wrapping a <code>Query</code> object with <code>_Expr</code> and passing it to the <code>FaunaClient</code> instance.</li><li><strong>CRUD methods</strong>: <code>aiofauna</code> provides CRUD operations out of the box: <ul><li><strong><code>get</code></strong>: instance coroutine that retrieves a single document by ref.</li><li><strong><code>find_unique</code></strong>: classmethod coroutine that retrieves a single document by a unique field.</li><li><strong><code>find_many</code></strong> to retrieve multiple documents by an indexed field.</li><li><code>all</code> to retrieve all documents from a collection.</li><li><code>create</code> to create a new document from an instance of the model.</li><li><code>save</code> to upsert a document from an instance of the model.</li><li><code>update</code> to update a document from the class object by providing the <code>ref</code> and the <code>data</code> to update as keyword arguments.</li><li><code>delete</code> to delete a document from the class object by providing the <code>ref</code> as a keyword argument.</li><li><code>delete_unique</code> to delete a document from the class object by providing the <code>ref</code> as a keyword argument.</li><li><code>exists</code> to check if a document exists by providing the <code>ref</code> as a keyword argument.</li><li><code>query</code> to query documents from the class object by providing the <code>Query</code> object as an string argument.</li><li><code>gen_ts</code> to generate the TypeScript definition for the model.</li><li><code>gen_store</code> to generate the Pinia store for the model.</li><li><code>provision</code> to provision the collection and indexes and unique constraints for the model based on the <code>ModelField</code> object created by the <code>Field</code> factory function metadata.</li><li>The <code>ref</code> and <code>ts</code> fields are optional properties that are created when a document instance is created on the database and forms part of the schema definition.</li><li>All the fields and properties are correctly serialized via custom encoders and decoders and the <code>ModelField</code> object is used to validate the data before it’s sent to the database.</li><li>The <code>ModelField</code> object is also used to generate the TypeScript definition for the model and the Pinia store.</li><li>The <code>ModelField</code> object is also used to provision the collection and indexes and unique constraints for the model.</li></ul></li></ul><h3>Why Aiohttp?</h3><ul><li>It’s a mature framework with a rich set of features built on top of asyncio and maintained by the Python Core Team.</li><li>It provides both sides of the coin, the server and the client, enabling you to build a full stack application with a single framework, there will be little need to use other frameworks or libraries.</li><li>It’s extensible through middlewares and plugins, since the ecosystem is so rich not enough known yet, it enabled developers to customize the DX and leverage the shortcomings and advantages of the framework.</li><li>It’s fast, since it’s built on top of asyncio and uvloop, it’s one of the fastest frameworks out there.</li><li><code>Application</code> is the main object often used as singleton that can be used to store global state and share it across the application. It’s <code>aiofauna</code> subclass <code>Api</code> enabled all the rich features provided by aiofauna such as automatic documentation, automatic serialization and deserialization of data between the database and the client, auto-provisioning, decorators, etc.</li><li><code>Request</code> object on REST endpoints is disoluted into the request signature in a FastAPI fashion way, by injecting directly the parameters into the endpoint function signature, according to the type annotations.</li><li><code>@sse</code> and <code>@webSocket</code> decorators with <code>path</code> and <code>query</code> params and no boilerplate code allow to explore further the capabilities of the framework by using Server Send Events and real time communication with WebSockets.</li><li><code>Swagger UI</code> can be accessed at <code>/docs</code> and speeds up development by providing quick feedback of the API that’s being developed.</li><li><code>OpenAPI</code> can be accessed at <code>/openapi.json</code> and can be used to generate the client code for the API.</li><li><code>HTTPClient</code> wraps <code>ClientSession</code> and provides a simple interface to make different kind of HTTP requests to third party resources allowing developers to build seamless integrations without extra boilerplate code or dependencies.</li></ul><h2>Why Pydantic?</h2><ul><li>This is such a retorical question, but I’ll answer it anyway, because it’s the best data validation library out there hands down.</li><li>It’s extensible through custom validators and types, so you can build your own validators and types and use them across your application.</li><li>It’s fast, since it’s built on top of dataclasses and uses the <code>__slots__</code> attribute to store the data, it’s one of the fastest data validation libraries out there.</li><li>It’s flexible, since it’s built on top of dataclasses, it’s easy to extend and customize.</li><li>It allows for some kind of metaprogramming through <code>ModelField</code> objects, so you can build your own custom validators and types and use them across your application.</li><li>It’s well documented and maintained by the community.</li></ul><br><br>",12),w="About",v=[{property:"og:title",content:"About"},{name:"twitter:title",content:"About"}],k={__name:"about",setup(p,{expose:t}){return t({frontmatter:{title:"About",meta:[{property:"og:title",content:"About"},{name:"twitter:title",content:"About"}]}}),a({title:"About",meta:[{property:"og:title",content:"About"},{name:"twitter:title",content:"About"}]}),(f,y)=>{const o=i("Icon");return s(),n("div",l,[e("div",r,[d(o,{icon:"mdi-information",class:"text-4xl text-primary -mb-2 m-auto"}),u]),h])}}};export{k as default,v as meta,w as title};
